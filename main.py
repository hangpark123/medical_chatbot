import gradio as gr
import os
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores.chroma import Chroma
from langchain.prompts.prompt import PromptTemplate
from langchain_community.llms import Ollama
from langchain.docstore.document import Document

# ë°ì´í„° ë¡œë”© ë° ë²¡í„° ì €ì¥ì†Œ ì„¤ì •
persist_directory = "chroma_db"

# CSV ë¡œë” ì„¤ì • ìˆ˜ì • (ë©”íƒ€ë°ì´í„° í¬í•¨)
loader = CSVLoader(
    file_path="/home/minsu/coding/medicine_update.csv",
    encoding='UTF-8',
    csv_args={
        'delimiter': ',',
        'quotechar': '"'
    },
    metadata_columns=['ì œí’ˆëª…', 'íš¨ëŠ¥']
)
docs = loader.load()

# ì„ë² ë”© ì„¤ì •
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    model_kwargs={'device': 'cuda'},
    encode_kwargs={'normalize_embeddings': True}
)

# í…ìŠ¤íŠ¸ ë¶„í• 
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
splits = text_splitter.split_documents(docs)

def process_in_batches(documents, embeddings, persist_directory, batch_size=5000):
    if not os.path.exists(persist_directory):
        vector_store = None
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            if vector_store is None:
                vector_store = Chroma.from_documents(batch, embeddings, persist_directory=persist_directory)
                vector_store.persist()
            else:
                vector_store.add_documents(batch)
        return vector_store
    else:
        return Chroma(persist_directory=persist_directory, embedding_function=embeddings)

vector_store = process_in_batches(splits, embeddings, persist_directory)

# retriever ì„¤ì •
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={
        "k": 10
    }
)

# Ollama ëª¨ë¸ ì´ˆê¸°í™”
chat_llm = Ollama(
    base_url='http://127.0.0.1:11434',
    model='kollama4'
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
request_prompt = PromptTemplate(
    template="""ë‹¹ì‹ ì€ ì œê³µëœ ì˜ì•½í’ˆ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì •í™•íˆ 3ê°œì˜ ì•½í’ˆì„ ì¶”ì²œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

    ì¦ìƒ: {question}
    
    ì•½í’ˆ ë°ì´í„°ë² ì´ìŠ¤:
    {context}
    
    [ê·œì¹™]
    1. ì •í™•íˆ 3ê°œì˜ ì•½í’ˆë§Œ ì¶”ì²œí•  ê²ƒ
    2. ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” ì œí’ˆëª…ê³¼ íš¨ëŠ¥ë§Œ ì‚¬ìš©í•  ê²ƒ
    3. ì œí’ˆëª…ê³¼ í•´ë‹¹ ì œí’ˆì˜ ì‹¤ì œ íš¨ëŠ¥ì„ ì •í™•íˆ ë§¤ì¹­í•  ê²ƒ
    4. ì¦ìƒê³¼ ê´€ë ¨ì´ ìˆëŠ” ì•½í’ˆë§Œ ì„ íƒí•  ê²ƒ
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
    
    [ë¶„ì„ëœ ì¦ìƒ]
    ì‚¬ìš©ìì˜ ì¦ìƒì— ëŒ€í•œ ê°„ë‹¨í•œ ë¶„ì„
    
    [ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì¶”ì²œ ì•½í’ˆ]
    1. [ì œí’ˆëª…]
    - íš¨ëŠ¥: [ì‹¤ì œ íš¨ëŠ¥ ë‚´ìš©]
    
    2. [ì œí’ˆëª…]
    - íš¨ëŠ¥: [ì‹¤ì œ íš¨ëŠ¥ ë‚´ìš©]
    
    3. [ì œí’ˆëª…]
    - íš¨ëŠ¥: [ì‹¤ì œ íš¨ëŠ¥ ë‚´ìš©]

    [ë³µìš© ì‹œ ì£¼ì˜ì‚¬í•­]
    ì•½í’ˆ ë³µìš© ì‹œ ì£¼ì˜í•´ì•¼ í•  ì ë“¤
    """,
    input_variables=['context', 'question']
)

def format_ret_docs(ret_docs):
    formatted_docs = []
    for doc in ret_docs:
        try:
            formatted_docs.append(f"ì œí’ˆëª…: {doc.metadata.get('ì œí’ˆëª…', '')}\níš¨ëŠ¥: {doc.metadata.get('íš¨ëŠ¥', '')}")
        except AttributeError:
            continue
    return "\n\n".join(formatted_docs)

# RAG ì²´ì¸ ì„¤ì •
rag_chain = (
    {'context': retriever | format_ret_docs, 'question': RunnablePassthrough()}
    | request_prompt
    | chat_llm
    | StrOutputParser()
)

def initialize_state():
    return {
        "chat_history": [(None, "ì•ˆë…•í•˜ì„¸ìš”. ì–´ë–¤ ì¦ìƒì´ ìˆìœ¼ì‹ ì§€ ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.")]
    }

def get_recommendation(message):
    try:
        response = rag_chain.invoke(message)
        return response
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def conversation(message, state):
    if state is None:
        state = initialize_state()
    
    chat_history = state["chat_history"]
    
    if message.strip().lower() == "ì²˜ìŒ":
        state = initialize_state()
        return "ì•ˆë…•í•˜ì„¸ìš”. ì–´ë–¤ ì¦ìƒì´ ìˆìœ¼ì‹ ì§€ ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.", state, state["chat_history"]
    
    response = get_recommendation(message)
    response += "\n\në‹¤ë¥¸ ì¦ìƒì„ ë¬¸ì˜í•˜ì‹œë ¤ë©´ 'ì²˜ìŒ'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    chat_history.append((message, response))
    return response, state, chat_history

# Gradio ì¸í„°í˜ì´ìŠ¤
with gr.Blocks(theme=gr.themes.Soft(
    primary_hue="blue",
    secondary_hue="gray",
), css="""
    .container {
        max-width: 1024px;
        margin: auto;
        padding: 0 2rem;
        height: 100vh;  /* ì „ì²´ ë†’ì´ ì‚¬ìš© */
    }
    #chatbot { 
        height: calc(100vh - 140px) !important;  /* ì±„íŒ…ì°½ ë†’ì´ ì¦ê°€ */
        overflow-y: auto;
        background-color: #ffffff;
        border-radius: 0;
        border: 1px solid #e5e7eb;
        box-shadow: none;
        margin: 0;
        padding: 1.5rem;
        font-size: 1.1rem;
    }
    #chatbot > div {
        padding: 0;
        max-width: 100%;
        min-height: calc(100vh - 200px);  /* ìµœì†Œ ë†’ì´ ì„¤ì • */
    }
    .message {
        padding: 2rem !important;
        border-bottom: 1px solid #e5e7eb !important;
        line-height: 1.7 !important;
        margin: 0.5rem 0 !important;
    }
    .message:last-child {
        border-bottom: none !important;
    }
    .user-message {
        background-color: #ffffff;
    }
    .bot-message {
        background-color: #f7f7f8;
    }
    .input-row {
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        background-color: #ffffff;
        border-top: 1px solid #e5e7eb;
        padding: 1rem;
        z-index: 100;
    }
    .input-container {
        max-width: 1024px;
        margin: auto;
        display: flex;
        gap: 1rem;
        align-items: center;
    }
    .input-box { 
        border: 1px solid #e5e7eb !important;
        border-radius: 0.75rem !important;
        padding: 1rem 1.25rem !important;
        font-size: 1.1rem !important;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05) !important;
        background-color: #ffffff !important;
        min-height: 50px !important;
    }
    .input-box:focus {
        outline: none !important;
        border-color: #2563eb !important;
        box-shadow: 0 0 0 2px rgba(37, 99, 235, 0.1) !important;
    }
    .send-btn, .clear-btn {
        padding: 0.75rem 1.5rem !important;
        border-radius: 0.5rem !important;
        font-size: 1rem !important;
        height: 50px !important;
    }
    .header {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        background-color: #ffffff;
        border-bottom: 1px solid #e5e7eb;
        padding: 1rem;
        z-index: 100;
        height: 60px;  /* í—¤ë” ë†’ì´ ê³ ì • */
    }
    .header-content {
        max-width: 1024px;
        margin: auto;
    }
    .content {
        margin-top: 60px;  /* í—¤ë” ë†’ì´ì™€ ë™ì¼ */
        margin-bottom: 80px;  /* ì…ë ¥ì°½ ë†’ì´ ê³ ë ¤ */
        min-height: calc(100vh - 140px);  /* ì „ì²´ ë†’ì´ì—ì„œ í—¤ë”ì™€ ì…ë ¥ì°½ ë†’ì´ ì œì™¸ */
        display: flex;
        flex-direction: column;
    }
""") as demo:
    with gr.Column(elem_classes="container"):
        gr.Markdown(
            """
            <div class="header-content">
                <h1 style="font-size: 1.5rem; font-weight: 600; color: #111827; margin: 0;">
                    ğŸ¥ AI í—¬ìŠ¤ì¼€ì–´ ì–´ì‹œìŠ¤í„´íŠ¸
                </h1>
            </div>
            """,
            elem_classes="header"
        )
        
        with gr.Column(elem_classes="content"):
            chatbot = gr.Chatbot(
                [],
                elem_id="chatbot",
                bubble_full_width=False,
                avatar_images=("/home/minsu/coding/user.png", "/home/minsu/coding/bot.png"),
                height=None,
            )

        with gr.Column(elem_classes="input-row"):
            with gr.Row(elem_classes="input-container"):
                msg = gr.Textbox(
                    placeholder="ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš”...",
                    show_label=False,
                    container=False,
                    elem_classes="input-box",
                    scale=20,
                )
                send_btn = gr.Button(
                    "ì „ì†¡",
                    variant="primary",
                    elem_classes="send-btn",
                    scale=2,
                )
                clear_btn = gr.Button(
                    "ìƒˆë¡œìš´ ìƒë‹´",
                    variant="secondary",
                    elem_classes="clear-btn",
                    scale=2,
                )

    state = gr.State(initialize_state())

    def clear_conversation():
        new_state = initialize_state()
        return new_state["chat_history"], new_state

    def handle_message(message, state):
        response, new_state, chat_history = conversation(message, state)
        return "", new_state, chat_history

    clear_btn.click(clear_conversation, [], [chatbot, state])
    send_btn.click(handle_message, [msg, state], [msg, state, chatbot])
    msg.submit(handle_message, [msg, state], [msg, state, chatbot])
    demo.load(lambda: initialize_state()["chat_history"], outputs=[chatbot])

if __name__ == "__main__":
    demo.launch(
        share=False,
        show_error=True,
        favicon_path="/home/minsu/coding/user.png"
    )
